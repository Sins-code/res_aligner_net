{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "muTruGCpicYL",
        "ECD58BA9iV2z"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6KJtaUSRGEJeLPGALUtpq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "<h1> Residual Aligner-based Network (RAN) for Coarse-to-fine Discontinuous Deformable Registration </h1>\n",
        "\n",
        "[![DOI](https://img.shields.io/badge/DOI-j.media.2023.103038-darkyellow)](https://doi.org/10.1016/j.media.2023.103038) \\|\n",
        "[![arXiv](https://img.shields.io/badge/arXiv-2203.04290-b31b1b.svg)](https://arxiv.org/abs/2203.04290) \\|\n",
        "<a href=\"https://github.com/jianqingzheng/res_aligner_net\"><img src=\"https://img.shields.io/github/stars/jianqingzheng/res_aligner_net?style=social&label=Code+★\" /></a>\n",
        "\\|\n",
        "[![Explore RAN in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jianqingzheng/res_aligner_net/blob/main/res_aligner_net.ipynb)\n",
        "\n",
        "</div>\n",
        "\n",
        "Code for *Medical Image Analysis* paper [Residual Aligner-based Network (RAN): Motion-Separable Structure for Coarse-to-fine Deformable Image Registration](https://doi.org/10.1016/j.media.2023.103038)\n",
        "\n",
        "\n",
        "> This repo provides an implementation of the training and inference pipeline of RAN based on TensorFlow and Keras.\n",
        "\n"
      ],
      "metadata": {
        "id": "b6wz3wqFgL7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Contents ###\n",
        "- 1. Installation\n",
        "- 2. Usage\n",
        "  - 2.1. Setup (for unpaired data)\n",
        "  - 2.2. Training (>1 week)\n",
        "  - 2.3. Inference\n",
        "  - 2.4. Visualization\n",
        "- 3. Citing this work\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "V2D7wQZaIc4K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO4x9NDrfGrm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 1. Installation {run: \"auto\"}\n",
        "#@markdown Clone code from Github repo: https://github.com/jianqingzheng/XBCR-net.git\n",
        "%cd /content\n",
        "\n",
        "!git clone https://github.com/jianqingzheng/res_aligner_net.git\n",
        "%cd res_aligner_net/\n",
        "\n",
        "#@markdown and Install packages\n",
        "\n",
        "import tensorflow as tf\n",
        "print('tf version: ',tf.__version__)\n",
        "\n",
        "!pip install pyquaternion==0.9.9\n",
        "\n",
        "#@markdown > `tensorflow==2.3.1` was the version originally used, but has changed here due to Colab compatibility issues.\\\n",
        "#@markdown > Other versions of the packages could also be applicable."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "HyrqH26JxUyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Usage"
      ],
      "metadata": {
        "id": "Mm0FbA_17vTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2.1. Setup (for unpaired data) ###\n",
        "```\n",
        "[$DOWNLOAD_DIR]/res_aligner_net/           \n",
        "├── data/[$data_name]/dataset\n",
        "|   |   # experimental dataset for training and testing (.nii|.nii.gz files)\n",
        "|   ├── train/\n",
        "|   |   ├── images/\n",
        "|   |   |   ├──0001.nii.gz\n",
        "|   |   |   └── ...\n",
        "|   |   ├── labels/\n",
        "|   |   |   ├──0001.nii.gz\n",
        "|   |   |   └── ...\n",
        "|   ├── test/\n",
        "|   |   ├── images/\n",
        "|   |   |   ├──0001.nii.gz\n",
        "|   |   |   └── ...\n",
        "|   |   └── labels/\n",
        "|   |       ├──0001.nii.gz\n",
        "|   |       └── ...\n",
        "└── models/[$data_name]/\n",
        "|   └── [$data_name]-[$model_name]/\n",
        "|       |   # the files of model parameters (.tf.index and .tf.data-000000-of-00001 files)\n",
        "|       ├── model_1_[$model_num].tf.index\n",
        "|       ├── model_1_[$model_num].tf.data-000000-of-00001\n",
        "|       └── ...\n",
        "└── ...\n",
        "```\n",
        "> The data used for experiments in this paper are publicly available from [abdomen CT](https://github.com/ucl-candi/datasets_deepreg_demo/archive/abdct.zip) and [lung CT](https://zenodo.org/record/3835682).\n",
        "\n"
      ],
      "metadata": {
        "id": "muTruGCpicYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown \\* Download data (default):\n",
        "data_name = 'unpaired_ct_abdomen' #@param [\"unpaired_ct_abdomen\",\"unpaired_ct_lung\"]\n",
        "\n",
        "if data_name == 'unpaired_ct_abdomen':\n",
        "  data_download_py=\"abd_data.py\"\n",
        "elif data_name == 'unpaired_ct_lung':\n",
        "  data_download_py=\"lung_data.py\"\n",
        "\n",
        "import os\n",
        "data_path='data'\n",
        "os.makedirs(os.path.join(data_path,data_name), exist_ok=True)\n",
        "\n",
        "!python external/deepreg/{data_download_py}\n",
        "!python main_preprocess.py --proc_type train --data_name {data_name}\n",
        "!python main_preprocess.py --proc_type test --data_name {data_name}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "obqYkcJeQZfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "nc6irIRCxSEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Training (>1 week) ###\n",
        "\n",
        "1. Run ```python main_train.py --model_name $model_name --data_name $data_name --max_epochs $max_epochs```\n",
        "2. Check the saved model in ```res_aligner_net/models/$data_name/$data_name-$model_name/```\n"
      ],
      "metadata": {
        "id": "ECD58BA9iV2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "| Argument              | Description                                \t|\n",
        "| --------------------- | ----------------------------------------------|\n",
        "| `--data_name` \t      | The data folder name                    |\n",
        "| `--model_name`        | The used model                      \t     \t|\n",
        "| `--max_epochs`        | The max epoch number for training \t     \t|\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "6AXf_gouKMVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown \\* Example for training (default):\n",
        "data_name = 'unpaired_ct_abdomen' #@param [\"unpaired_ct_abdomen\",\"unpaired_ct_lung\"]\n",
        "model_name = 'RAN4' #@param {type:\"string\"}\n",
        "max_epochs = 0  #@param {type:\"integer\"}\n",
        "\n",
        "!python main_train.py --model_name {model_name} --data_name {data_name} --max_epochs {max_epochs}\n",
        "\n",
        "#@markdown > `max_epochs=0` indicates training from scratch. \\\n",
        "#@markdown > Training from scratch would take more than 1 week,\n",
        "#@markdown > which may not be possible in this demo\n",
        "#@markdown > (the usage time limit in Colab is <12/24 hours).\n"
      ],
      "metadata": {
        "id": "gUvY0DiSi-RD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "HH7rcmijxQmV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. Inference ###\n",
        "1. Run ```python main_infer.py --model_name $model_name --data_name $data_name```\n",
        "2. Check the results in ```res_aligner_net/data/$data_name/dataset/test/```"
      ],
      "metadata": {
        "id": "s5JFReKFDyPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "| Argument              | Description                                \t|\n",
        "| --------------------- | ----------------------------------------------|\n",
        "| `--data_name` \t| The data folder name                       \t|\n",
        "| `--model_name`        | The used model                      \t     \t|\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "c4HnhkXU_Nld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown \\* Example for inference (default):\n",
        "data_name = 'unpaired_ct_abdomen' #@param [\"unpaired_ct_abdomen\",\"unpaired_ct_lung\"]\n",
        "model_name = 'RAN4' #@param {type:\"string\"}\n",
        "model_id = \"2\" #@param [\"1\",\"2\",\"3\"]\n",
        "\n",
        "!python main_infer.py --model_name {model_name} --model_id {model_id} --data_name {data_name}\n",
        "\n",
        "#@markdown > `model_id==1` for a model after synthetic training,\n",
        "#@markdown > `model_id==2` for a model after real training,\n",
        "#@markdown > `model_id==3` for the model trained according to paper's settings\n",
        "#@markdown > (seems to be incompatible with the version of TensorFlow/Keras in Colab)."
      ],
      "metadata": {
        "id": "Av3PcKSNFMxv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown \\* Download the result file (after inference).\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "download_path = os.path.join('data',data_name,'dataset','test_proc','warped_img')\n",
        "\n",
        "!zip -r results.zip {download_path}/*\n",
        "files.download(f\"results.zip\")\n",
        "# files.download(download_path)\n",
        "print('Download the results from: '+download_path)"
      ],
      "metadata": {
        "id": "XcIc7RaABHDD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "cellView": "form",
        "outputId": "cadc82a3-90e2-49e1-e7f0-8343566a885f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_90313364-cca0-4c37-b387-775f91d69f33\", \"results.zip\", 158022570)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download the results from: data/unpaired_ct_abdomen/dataset/test_proc/warped_img\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "YAXj7i_ZxMdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.4 Visualization\n",
        "\n",
        "target_id = 0 #@param {type:\"integer\"}\n",
        "source_id = 1 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown > visualize the original image with id=`target_id` when `target_id==source_id`\\\n",
        "#@markdown > visualize the warped image with `target_id` and `source_id` when `target_id!=source_id`\n",
        "\n",
        "download_path = os.path.join('data',data_name,'dataset','test_proc','warped_img')\n",
        "\n",
        "if target_id == source_id:\n",
        "  img_path = os.path.join(download_path,'img_target_'+str(target_id)+'.nii')\n",
        "else:\n",
        "  img_path = os.path.join(download_path,'img_warped_'+str(model_name)+'_'+str(target_id)+'_from_'+str(source_id)+'.nii')\n",
        "\n",
        "\n",
        "from os.path import dirname, join\n",
        "from pprint import pprint\n",
        "import numpy as np\n",
        "import ipywidgets as ipyw\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "class ImageSliceViewer3D:\n",
        "  \"\"\"\n",
        "  ImageSliceViewer3D is for viewing volumetric image slices in jupyter or\n",
        "  ipython notebooks.\n",
        "\n",
        "  User can interactively change the slice plane selection for the image and\n",
        "  the slice plane being viewed.\n",
        "Arguments:\n",
        "  Volume = 3D input image\n",
        "  figsize = default(8,8), to set the size of the figure\n",
        "  cmap = default('gray'), string for the matplotlib colormap. You can find\n",
        "  more matplotlib colormaps on the following link:\n",
        "  https://matplotlib.org/users/colormaps.html\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, volume, figsize=(100,100), cmap='gray'):\n",
        "    self.volume = volume\n",
        "    self.figsize = figsize\n",
        "    self.cmap = cmap\n",
        "    self.v = [np.min(volume), np.max(volume)]\n",
        "\n",
        "    # Call to select slice plane\n",
        "    ipyw.interact(self.views)\n",
        "\n",
        "  def views(self):\n",
        "    self.vol1 = np.transpose(self.volume, [1,2,0])\n",
        "    self.vol2 = np.rot90(np.transpose(self.volume, [2,0,1]), 3) #rotate 270 degrees\n",
        "    self.vol3 = np.transpose(self.volume, [0,1,2])\n",
        "    maxZ1 = self.vol1.shape[2] - 1\n",
        "    maxZ2 = self.vol2.shape[2] - 1\n",
        "    maxZ3 = self.vol3.shape[2] - 1\n",
        "    ipyw.interact(self.plot_slice,\n",
        "        z1=ipyw.IntSlider(min=0, max=maxZ1, step=1, continuous_update=False,\n",
        "        description='Axial:'),\n",
        "        z2=ipyw.IntSlider(min=0, max=maxZ2, step=1, continuous_update=False,\n",
        "        description='Coronal:'),\n",
        "        z3=ipyw.IntSlider(min=0, max=maxZ3, step=1, continuous_update=False,\n",
        "        description='Sagittal:'))\n",
        "  def plot_slice(self, z1, z2, z3):\n",
        "    # Plot slice for the given plane and slice\n",
        "    f,ax = plt.subplots(1,3, figsize=self.figsize)\n",
        "    #print(self.figsize)\n",
        "    #self.fig = plt.figure(figsize=self.figsize)\n",
        "    #f(figsize = self.figsize)\n",
        "    ax[0].imshow(self.vol1[:,:,z1], cmap=plt.get_cmap(self.cmap),\n",
        "        vmin=self.v[0], vmax=self.v[1])\n",
        "    ax[1].imshow(self.vol2[:,:,z2], cmap=plt.get_cmap(self.cmap),\n",
        "        vmin=self.v[0], vmax=self.v[1])\n",
        "    ax[2].imshow(self.vol3[:,:,z3], cmap=plt.get_cmap(self.cmap),\n",
        "        vmin=self.v[0], vmax=self.v[1])\n",
        "    plt.show()\n",
        "\n",
        "ImageSliceViewer3D(nib.load(img_path).slicer[:,:,:].get_fdata())\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jvoXdfGZvJFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "EtbePvYAxOjF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Citing this work\n",
        "\n",
        "Any publication that discloses findings arising from using this source code or the network model should cite:\n",
        "- Zheng, J. Q., Wang, Z., Huang, B., Lim, N. H., & Papież, B. W. \"Residual Aligner-based Network (RAN): Motion-separable structure for coarse-to-fine discontinuous deformable registration.\" *Medical Image Analysis*, 2024, 91: 103038.\n",
        "```bibtex\n",
        "@article{ZHENG2024103038,\n",
        "\ttitle = {Residual Aligner-based Network (RAN): Motion-separable structure for coarse-to-fine discontinuous deformable registration},\n",
        "\tjournal = {Medical Image Analysis},\n",
        "\tvolume = {91},\n",
        "\tpages = {103038},\n",
        "\tyear = {2024},\n",
        "\tissn = {1361-8415},\n",
        "\tdoi = {https://doi.org/10.1016/j.media.2023.103038},\n",
        "\turl = {https://www.sciencedirect.com/science/article/pii/S1361841523002980},\n",
        "\tauthor = {Jian-Qing Zheng and Ziyang Wang and Baoru Huang and Ngee Han Lim and Bartłomiej W. Papież},\n",
        "\tkeywords = {Discontinuous deformable registration, Motion-separable structure, Motion disentanglement, Coarse-to-fine registration},\n",
        "}\n",
        "```\n"
      ],
      "metadata": {
        "id": "Dg0PMCfSwcXx"
      }
    }
  ]
}
